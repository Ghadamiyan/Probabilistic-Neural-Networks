{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-TpfsG4P6HT"
   },
   "source": [
    "# **Second Project PP (part3)**\n",
    "\n",
    "Ghadamiyan Lida 407 AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_21YVDYSQUtP"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylUqmh7HP42Y",
    "outputId": "4d66ccf6-6b45-4ad9-fdfb-66224eeb3193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymc in /usr/local/lib/python3.6/dist-packages (2.3.8)\n",
      "Requirement already satisfied: arviz in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
      "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.6/dist-packages (from arviz) (51.3.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from arviz) (3.2.2)\n",
      "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.5.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from arviz) (20.8)\n",
      "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.1.5)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.4.1)\n",
      "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from arviz) (0.16.2)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from arviz) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->arviz) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->arviz) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->arviz) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->arviz) (1.3.1)\n",
      "Requirement already satisfied: cftime in /usr/local/lib/python3.6/dist-packages (from netcdf4->arviz) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->arviz) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0->arviz) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymc\n",
    "\n",
    "#Loading libraries                                                         \n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from pymc3.theanof import MRG_RandomStreams, set_tt_rng\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "floatX = theano.config.floatX\n",
    "filterwarnings(\"ignore\")\n",
    "sns.set_style(\"white\") \n",
    "\n",
    "! pip install arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57T8RHiQQglG"
   },
   "source": [
    "# Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vriuLERGQnVo"
   },
   "outputs": [],
   "source": [
    "X, Y = make_moons(noise=0.2, random_state=0, n_samples=1000)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "Y = Y.astype(floatX)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPQh89oDQwDR"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lkEr6ZdPSCMe"
   },
   "outputs": [],
   "source": [
    "# function for building the binary bayesian neural network\n",
    "def build_bbnn(bbnn_input, bbnn_output, bbnn_input2, bbnn_output2 ,nn_input, nn_output, hidden_layers):\n",
    "\n",
    "    with pm.Model() as bneural_network:\n",
    "        bbnn_input = pm.Data(\"bbnn_input\", bbnn_input)\n",
    "        bbnn_output = pm.Data(\"bbnn_output\", bbnn_output)\n",
    "\n",
    "        # Prior on weights and biases for the first NN\n",
    "\n",
    "        # Prior on biases\n",
    "        biases = pm.Normal('biases', 0, 1, shape = (2, ))\n",
    "\n",
    "        # Prior on weights from input to the hidden layer\n",
    "        weights1 = pm.Normal(\"weights1\", 0, 1, shape=(nn_input.shape[1], hidden_layers), \n",
    "                            testval = np.random.randn(nn_input.shape[1], hidden_layers)*np.sqrt(2/hidden_layers).astype(floatX))\n",
    "\n",
    "        # Prior on weights from the first to the second hidden layer\n",
    "        weights2 = pm.Normal(\"weights2\", 0, 1, shape=(hidden_layers,), \n",
    "                            testval = np.random.randn(hidden_layers)*np.sqrt(2/hidden_layers).astype(floatX))\n",
    "\n",
    "        # Hyperbolic tangent as activation function\n",
    "        activation1 = pm.math.tanh(pm.math.dot(bbnn_input, weights1) + biases[0])\n",
    "        activationOut = pm.math.sigmoid(pm.math.dot(activation1, weights2) + biases[1])\n",
    "\n",
    "        #############################################################################################################################################\n",
    "        bbnn_input2 = pm.Data(\"bbnn_input2\", bbnn_input2)\n",
    "        bbnn_output2 = pm.Data(\"bbnn_output2\", bbnn_output2)\n",
    "\n",
    "\n",
    "        # Prior on weights and biases for the second NN\n",
    "\n",
    "        # Prior on biases\n",
    "        biases2 = pm.Normal('biases2', 0, 1, shape = (2, ))\n",
    "\n",
    "        # Prior on weights from input to the hidden layer\n",
    "        weights12 = pm.Normal(\"weights12\", 0, 1, shape=(nn_input.shape[1], hidden_layers), \n",
    "                            testval = np.random.randn(nn_input.shape[1], hidden_layers)*np.sqrt(2/hidden_layers).astype(floatX))\n",
    "\n",
    "        # Prior on weights from the first to the second hidden layer\n",
    "        weights22 = pm.Normal(\"weights22\", 0, 1, shape=(hidden_layers,), \n",
    "                            testval = np.random.randn(hidden_layers)*np.sqrt(2/hidden_layers).astype(floatX))\n",
    "\n",
    "        # Hyperbolic tangent as activation function\n",
    "        activation12 = pm.math.tanh(pm.math.dot(bbnn_input2, weights12) + biases2[0])\n",
    "        activationOut2 = pm.math.sigmoid(pm.math.dot(activation12, weights22) + biases2[1])\n",
    "\n",
    "        ###############################################################################################################################################\n",
    "        unif = pm.Normal('unif', 0, 1, total_size = len(nn_output))\n",
    "\n",
    "\n",
    "        activationUnif = pm.math.sigmoid(pm.math.dot((activationOut2+activationOut), unif))\n",
    "\n",
    "        \n",
    "        output = pm.Bernoulli('output', activationUnif, observed = bbnn_output2, total_size = len(nn_output))\n",
    "    return bneural_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orkWvtLPTpGO",
    "outputId": "1a56ca8c-0365-4498-994c-b84b365b0a0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "Average Loss = 1.7144: 100%|██████████| 5000/5000 [00:07<00:00, 705.99it/s]\n",
      "Finished [100%]: Average Loss = 1.7139\n"
     ]
    }
   ],
   "source": [
    "bneural_network = build_bbnn(X_train, Y_train, X_train, Y_train, X_train, Y_train , 10)\n",
    "set_tt_rng(MRG_RandomStreams(42))\n",
    "\n",
    "with bneural_network:\n",
    "    inference = pm.ADVI()\n",
    "    approx = pm.fit(n=5000, method=inference)\n",
    "trace = approx.sample(draws=100)\n",
    "\n",
    "x = T.matrix(\"X\")\n",
    "n = T.iscalar(\"n\")\n",
    "\n",
    "x.tag.test_value = np.empty_like(X_test[:10])\n",
    "n.tag.test_value = 100\n",
    "_sample_proba = approx.sample_node(\n",
    "    bneural_network.output.distribution.p, size=n, more_replacements={bneural_network[\"bbnn_input\"]: x}\n",
    ")\n",
    "sample_proba = theano.function([x, n], _sample_proba, on_unused_input='ignore')\n",
    "pred = sample_proba(X_test, 1000).mean(0) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9Hx3nIEo7fm",
    "outputId": "b032f4b2-b38b-429d-f3a7-f6b7eb3816c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_21YVDYSQUtP",
    "57T8RHiQQglG"
   ],
   "name": "Siamese BNN .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
